{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Build a CNN for image recognition.\n",
    "\n",
    "## Due Date:  March 27, 11:59PM\n",
    "\n",
    "### Name: Atul Gupta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "\n",
    "1. In this assignment, you will build Convolutional Neural Network to classify CIFAR-10 Images.\n",
    "2. You can directly load dataset from many deep learning packages.\n",
    "3. You can use any deep learning packages such as pytorch, keras or tensorflow for this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements:\n",
    "\n",
    "1. You need to load cifar 10 data and split the entire training dataset into training and validation.\n",
    "2. You will implement a CNN model to classify cifar 10 images with provided structure.\n",
    "3. You need to plot the training and validation accuracy or loss obtained from above step.\n",
    "4. Then you can use tuned parameters to train using the entire training dataset.\n",
    "5. You should report the testing accuracy using the model with complete data.\n",
    "6. You may try to change the structure (e.g, add BN layer or dropout layer,...) and analyze your findings.\n",
    "\n",
    "## Google Colab\n",
    "\n",
    "- If you do not have GPU, the training of a CNN can be slow. Google Colab is a good option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalization (BN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Batch Normalization is a technique to speed up training and help make the model more stable.\n",
    "- In simple words, batch normalization is just another network layer that gets inserted between a hidden layer and the next hidden layer. Its job is to take the outputs from the first hidden layer and normalize them before passing them on as the input of the next hidden layer.\n",
    "\n",
    "- For more detailed information, you may refer to the original paper: https://arxiv.org/pdf/1502.03167.pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BN Algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input: Values of $x$ over a mini-batch: $\\mathbf{B}$ = $\\{x_1,..., x_m\\};$\n",
    "- Output: $\\{y_i = BN_{\\gamma,\\beta}(x_i)\\}$, $\\gamma, \\beta$ are learnable parameters\n",
    "\n",
    "Normalization of the Input:\n",
    "$$\\mu_{\\mathbf{B}} = \\frac{1}{m}\\sum_{i=1}^m x_i$$\n",
    "$$\\sigma_{\\mathbf{B}}^2 = \\frac{1}{m}\\sum_{i=1}^m (x_i - \\mu_{\\mathbf{B}})^2$$\n",
    "$$\\hat{x_i} = \\frac{x_i - \\mu_{\\mathbf{B}}}{\\sqrt{\\sigma_{\\mathbf{B}}}^2 + \\epsilon}$$\n",
    "Re-scaling and Offsetting:\n",
    "$$y_i = \\gamma \\hat{x_i} + \\beta = BN_{\\gamma,\\beta}(x_i)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages of BN:\n",
    "1. Improves gradient flow through the network.\n",
    "2. Allows use of saturating nonlinearities and higher learning rates.\n",
    "3. Makes weights easier to initialize.\n",
    "4. Act as a form of regularization and may reduce the need for dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The batch normalization layer has already been implemented in many packages. You may simply call the function to build the layer. For example: torch.nn.BatchNorm2d() using pytroch package, keras.layers.BatchNormalization() using keras package.\n",
    "- The location of BN layer: Please make sure ```BatchNormalization``` is between a ```Conv```/```Dense``` layer and an ```activation``` layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-28 14:05:24.903524: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train: (50000, 32, 32, 3)\n",
      "shape of y_train: (50000, 1)\n",
      "shape of x_test: (10000, 32, 32, 3)\n",
      "shape of y_test: (10000, 1)\n",
      "number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "# Load Cifar-10 Data\n",
    "# This is just an example, you may load dataset from other packages.\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import models,layers\n",
    "\n",
    "### If you can not load keras dataset, un-comment these two lines.\n",
    "#import ssl\n",
    "#ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print('shape of x_train: ' + str(x_train.shape))\n",
    "print('shape of y_train: ' + str(y_train.shape))\n",
    "print('shape of x_test: ' + str(x_test.shape))\n",
    "print('shape of y_test: ' + str(y_test.shape))\n",
    "print('number of classes: ' + str(np.max(y_train) - np.min(y_train) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. One-hot encode the labels (5 points)\n",
    "\n",
    "In the input, a label is a scalar in $\\{0, 1, \\cdots , 9\\}$. One-hot encode transform such a scalar to a $10$-dim vector. E.g., a scalar ```y_train[j]=3``` is transformed to the vector ```y_train_vec[j]=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]```.\n",
    "\n",
    "1. Implement a function ```to_one_hot``` that transforms an $n\\times 1$ array to a $n\\times 10$ matrix.\n",
    "\n",
    "2. Apply the function to ```y_train``` and ```y_test```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train_vec: (50000, 10)\n",
      "Shape of y_test_vec: (10000, 10)\n",
      "[6]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "def to_one_hot(y, num_class=10):\n",
    "    encoded = np.zeros(shape=(y.shape[0],num_class))\n",
    "    encoded[np.arange(y.shape[0]),y.ravel()] = 1\n",
    "    return encoded\n",
    "        \n",
    "\n",
    "y_train_vec = to_one_hot(y_train)\n",
    "y_test_vec = to_one_hot(y_test)\n",
    "\n",
    "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
    "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
    "\n",
    "print(y_train[0])\n",
    "print(y_train_vec[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remark: the outputs should be\n",
    "* Shape of y_train_vec: (50000, 10)\n",
    "* Shape of y_test_vec: (10000, 10)\n",
    "* [6]\n",
    "* [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Randomly partition the training set to training and validation sets (5 points)\n",
    "\n",
    "Randomly partition the 50K training samples to 2 sets: \n",
    "* a training set containing 40K samples: x_tr, y_tr\n",
    "* a validation set containing 10K samples: x_val, y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_tr: (40000, 32, 32, 3)\n",
      "Shape of y_tr: (40000, 10)\n",
      "Shape of x_val: (10000, 32, 32, 3)\n",
      "Shape of y_val: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "x_tr,x_val,y_tr,y_val = train_test_split(x_train,y_train_vec,test_size=0.2,random_state=43)\n",
    "\n",
    "\n",
    "print('Shape of x_tr: ' + str(x_tr.shape))\n",
    "print('Shape of y_tr: ' + str(y_tr.shape))\n",
    "print('Shape of x_val: ' + str(x_val.shape))\n",
    "print('Shape of y_val: ' + str(y_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build a CNN and tune its hyper-parameters (50 points)\n",
    "\n",
    "- Build a convolutional neural network model using the below structure:\n",
    "\n",
    "- It should have a structure of: Conv - ReLU - Max Pool - ConV - ReLU - Max Pool - Dense - ReLU - Dense - Softmax\n",
    "\n",
    "- In the graph 3@32x32 means the dimension of input image, 32@30x30 means it has 32 filters and the dimension now becomes 30x30 after the convolution.\n",
    "- All convolutional layers (Conv) should have stride = 1 and no padding.\n",
    "- Max Pooling has a pool size of 2 by 2.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"network.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You may use the validation data to tune the hyper-parameters (e.g., learning rate, and optimization algorithm)\n",
    "- Do NOT use test data for hyper-parameter tuning!!!\n",
    "- Try to achieve a validation accuracy as high as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "\n",
    "def build_model(hp):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (4, 4), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    hp_optimizer = hp.Choice('optimizer', values=['adam', 'rmsprop', 'sgd', 'adagrad', 'adamax'])\n",
    "\n",
    "    optimizer = {\n",
    "      'adam':keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "      'rmsprop': keras.optimizers.RMSprop(learning_rate=hp_learning_rate),\n",
    "      'sgd': keras.optimizers.SGD(learning_rate=hp_learning_rate),\n",
    "      'adagrad': keras.optimizers.Adagrad(learning_rate=hp_learning_rate),\n",
    "      'adamax': keras.optimizers.Adamax(learning_rate=hp_learning_rate)\n",
    "    }[hp_optimizer]\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q -U keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir/atul_assign2/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "# Define model optimizer and loss function\n",
    "import keras_tuner as kt\n",
    "tuner = kt.Hyperband(build_model,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=100,\n",
    "                     factor=3,\n",
    "                     directory='my_dir',\n",
    "                     project_name='atul_assign2')\n",
    "\n",
    "stop_early = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model and store model parameters/loss values\n",
    "tuner.search(x_tr, y_tr, epochs=100, validation_data=(x_val, y_val), callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Optimizer: adamax\n",
      "Best Learning Rate: 0.001\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Optimizer:\", best_hps.get('optimizer'))\n",
    "print(\"Best Learning Rate:\", best_hps.get('learning_rate'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-28 14:05:30.436630: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 2.6241 - accuracy: 0.2671 - val_loss: 1.7259 - val_accuracy: 0.3723\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 1.5630 - accuracy: 0.4458 - val_loss: 1.5386 - val_accuracy: 0.4629\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 1.3347 - accuracy: 0.5304 - val_loss: 1.4010 - val_accuracy: 0.5145\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 1.1714 - accuracy: 0.5919 - val_loss: 1.2744 - val_accuracy: 0.5543\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.0270 - accuracy: 0.6432 - val_loss: 1.1496 - val_accuracy: 0.6013\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.8905 - accuracy: 0.6903 - val_loss: 1.1631 - val_accuracy: 0.6115\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 0.7608 - accuracy: 0.7378 - val_loss: 1.1546 - val_accuracy: 0.6236\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 0.6291 - accuracy: 0.7839 - val_loss: 1.1958 - val_accuracy: 0.6338\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 0.5128 - accuracy: 0.8237 - val_loss: 1.2594 - val_accuracy: 0.6346\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 0.4010 - accuracy: 0.8631 - val_loss: 1.3131 - val_accuracy: 0.6396\n",
      "Epoch 10: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(x_tr, y_tr, epochs=100, validation_data=(x_val, y_val), callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 12, 12, 64)        32832     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               590080    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 626,378\n",
      "Trainable params: 626,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 10\n"
     ]
    }
   ],
   "source": [
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Plot the training and validation loss curve versus epochs. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curve\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "epochs = history.epoch\n",
    "train_acc = history.history['accuracy']\n",
    "valid_acc = history.history['val_accuracy']\n",
    "plt.plot(epochs, train_acc, 'bo', label='Training Accuracy')\n",
    "plt.plot(epochs, valid_acc, 'r', label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train (again) and evaluate the model (5 points)\n",
    "\n",
    "- To this end, you have found the \"best\" hyper-parameters. \n",
    "- Now, fix the hyper-parameters and train the network on the entire training set (all the 50K training samples)\n",
    "- Evaluate your model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model on the entire training set\n",
    "\n",
    "Why? Previously, you used 40K samples for training; you wasted 10K samples for the sake of hyper-parameter tuning. Now you already know the hyper-parameters, so why not using all the 50K samples for training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<Compile your model again (using the same hyper-parameters you tuned above)>\n",
    "hypermodel = tuner.hypermodel.build(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.6431 - accuracy: 0.2999\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 1.4714 - accuracy: 0.4774\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 1.2446 - accuracy: 0.5611\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 1.0518 - accuracy: 0.6363\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.8994 - accuracy: 0.6884\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.7544 - accuracy: 0.7407\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.6271 - accuracy: 0.7847\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.4992 - accuracy: 0.8293\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.3894 - accuracy: 0.8656\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.2886 - accuracy: 0.9030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb7a4bef9a0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#<Train your model on the entire training set (50K samples)>\n",
    "hypermodel.fit(x_train, y_train_vec, epochs=best_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate the model on the test set (5 points)\n",
    "\n",
    "Do NOT used the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 1.3045 - accuracy: 0.6711\n"
     ]
    }
   ],
   "source": [
    "# Evaluate your model performance (testing accuracy) on testing data.\n",
    "eval_result = hypermodel.evaluate(x_test, y_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6711000204086304\n",
      "Test Loss: 1.3045134544372559\n"
     ]
    }
   ],
   "source": [
    "print('Test Accuracy:', eval_result[1])\n",
    "print('Test Loss:', eval_result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Building model with new structure (25 points)\n",
    "- In this section, you can build your model with adding new layers (e.g, BN layer or dropout layer, ...)\n",
    "- If you want to regularize a ```Conv/Dense layer```, you should place a ```Dropout layer``` before the ```Conv/Dense layer```.\n",
    "- You can try to compare their loss curve and testing accuracy and analyze your findings.\n",
    "- You need to try at lease two different structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.3307 - accuracy: 0.5259\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.0326 - accuracy: 0.6377\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 0.9114 - accuracy: 0.6775\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 0.8352 - accuracy: 0.7043\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 0.7750 - accuracy: 0.7278\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 0.7285 - accuracy: 0.7450\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 0.6844 - accuracy: 0.7589\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6447 - accuracy: 0.7735\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 2098s 1s/step - loss: 0.6123 - accuracy: 0.7856\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.5884 - accuracy: 0.7934\n",
      "313/313 [==============================] - 2s 4ms/step - loss: 0.7602 - accuracy: 0.7428\n",
      "Test Accuracy: 0.7427999973297119\n",
      "Test Loss: 0.7601625919342041\n"
     ]
    }
   ],
   "source": [
    "new_model_one = models.Sequential()\n",
    "new_model_one.add(layers.Conv2D(32, (3, 3), input_shape=(32, 32, 3)))\n",
    "new_model_one.add(layers.BatchNormalization())\n",
    "new_model_one.add(layers.Activation('relu'))\n",
    "new_model_one.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "new_model_one.add(layers.Conv2D(64, (4, 4)))\n",
    "new_model_one.add(layers.BatchNormalization())\n",
    "new_model_one.add(layers.Activation('relu'))\n",
    "new_model_one.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "new_model_one.add(layers.Flatten())\n",
    "new_model_one.add(layers.Dropout(0.5))\n",
    "new_model_one.add(layers.Dense(256))\n",
    "new_model_one.add(layers.BatchNormalization())\n",
    "new_model_one.add(layers.Activation('relu'))\n",
    "new_model_one.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "new_model_one.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "new_model_one.fit(x_train, y_train_vec, epochs=best_epoch)\n",
    "\n",
    "eval_result_one = new_model_one.evaluate(x_test, y_test_vec)\n",
    "print('Test Accuracy:', eval_result_one[1])\n",
    "print('Test Loss:', eval_result_one[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 1.5118 - accuracy: 0.4555\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 1.2075 - accuracy: 0.5724\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 1.0848 - accuracy: 0.6182\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 1.0074 - accuracy: 0.6497\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.9396 - accuracy: 0.6733\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.8907 - accuracy: 0.6906\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.8453 - accuracy: 0.7064\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.8059 - accuracy: 0.7199\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.7820 - accuracy: 0.7282\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.7547 - accuracy: 0.7379\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.9843 - accuracy: 0.6672\n",
      "Test Accuracy: 0.6672000288963318\n",
      "Test Loss: 0.9843122959136963\n"
     ]
    }
   ],
   "source": [
    "new_model_two = models.Sequential()\n",
    "new_model_two.add(layers.Conv2D(32, (3, 3), input_shape=(32, 32, 3)))\n",
    "new_model_two.add(layers.BatchNormalization())\n",
    "new_model_two.add(layers.Activation('relu'))\n",
    "new_model_two.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "new_model_two.add(layers.Conv2D(64, (4, 4)))\n",
    "new_model_two.add(layers.BatchNormalization())\n",
    "new_model_two.add(layers.Activation('relu'))\n",
    "new_model_two.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "new_model_two.add(layers.Conv2D(128, (4, 4)))\n",
    "new_model_two.add(layers.BatchNormalization())\n",
    "new_model_two.add(layers.Activation('relu'))\n",
    "new_model_two.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "new_model_two.add(layers.Flatten())\n",
    "new_model_two.add(layers.Dropout(0.5))\n",
    "new_model_two.add(layers.Dense(512))\n",
    "new_model_two.add(layers.BatchNormalization())\n",
    "new_model_two.add(layers.Activation('relu'))\n",
    "new_model_two.add(layers.Dense(10, activation='sigmoid'))\n",
    "\n",
    "new_model_two.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "new_model_two.fit(x_train, y_train_vec, epochs=best_epoch)\n",
    "\n",
    "eval_result_two = new_model_two.evaluate(x_test, y_test_vec)\n",
    "print('Test Accuracy:', eval_result_two[1])\n",
    "print('Test Loss:', eval_result_two[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for the original model: 0.6711000204086304\n",
      "Accuracy for the first new model: 0.7427999973297119\n",
      "Accuracy for the second new model: 0.6672000288963318\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy for the original model:', eval_result[1])\n",
    "print('Accuracy for the first new model:', eval_result_one[1])\n",
    "print('Accuracy for the second new model:', eval_result_two[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
